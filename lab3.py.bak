# import cognitive_face as CF
import requests
import cv2
import cognitive_face as CF
import numpy as np
from io import BytesIO
# from PIL import Image, ImageDraw
from flask import Flask, render_template, jsonify, request, redirect, url_for, session
from KEYS import CF_KEY
from werkzeug.utils import secure_filename
from flask_oauth import OAuth

GOOGLE_CLIENT_ID = '544478068590-eveudh44t7l8rl4ruvoj3qd3b875ne4k.apps.googleusercontent.com'
GOOGLE_CLIENT_SECRET = 'SAZ3LN0fucu4GN_90heFQBf4'
REDIRECT_URI = '/oauth2callback'


app = Flask(__name__)
oauth = OAuth()

if (__name__ == '__main__'):
   app.run(
       debug=True,
   )

CF.Key.set(CF_KEY)

BASE_URL = 'https://eastus.api.cognitive.microsoft.com/face/v1.0/'  # Replace with your regional Base URL
CF.BaseUrl.set(BASE_URL)

google = oauth.remote_app('google',
base_url='https://www.google.com/accounts/',
authorize_url='https://accounts.google.com/o/oauth2/auth',
request_token_url=None,
request_token_params={'scope': 'https://www.googleapis.com/auth/userinfo.email',
'response_type': 'code'},
access_token_url='https://accounts.google.com/o/oauth2/token',
access_token_method='POST',
access_token_params={'grant_type': 'authorization_code'},
consumer_key=GOOGLE_CLIENT_ID,
consumer_secret=GOOGLE_CLIENT_SECRET)

app.config['UPLOAD_FOLDER'] = '/Uploads'


TotalEmotionAverage = {'anger': [], 'contempt': [], 'disgust': [], 'fear': [], 'happiness': [], 'neutral': [], 'sadness': [], 'surprise': []}

@app.route("/")
def homepage():
    return render_template("index.html")

@app.route("/return", methods=['GET', 'POST'])
def retpage():
    if request.method == 'POST':
        vid= request.files['vide']
        # print(vid.filename)
        vid.save(secure_filename(vid.filename))
        # analysis = forLab(vid.filename)
        analysis = findEmotions(vid.filename, 40)
        return render_template("index.html", vid=analysis[1], highest=analysis[0])
    else:
        return render_template("index.html")

def findEmotions(vid, turns):
    assert turns >= 0, "Cannot have negative turn value"
    cap = cv2.VideoCapture(vid)
    turnsLeft = 0
    while(cap.isOpened()):
        ret, frame = cap.read()
        if ret:
            cv2.imwrite("current.png", frame)
            # TODO: only make API call once every x turns
            if turnsLeft != 0:
                turnsLeft -= 1
            else:
                result = CF.face.detect("current.png", attributes='emotion')
                try:
                    if len(result) > 0:
                        emoList = []
                        for face in result:
                            emotes = face['faceAttributes']['emotion']
                            print(emotes)
                            emoList.append(emotes)

                            # TODO: if there is more than one face, average out emotion
                            # for now we'll take the first one
                        emo = emoList[0]
            
                    else:
                        continue
                    
                    for key in emo:
                        TotalEmotionAverage[key].append(emo[key])


                    # TODO: emotion calculation -> effects
                    highestEmotion = max(emo, key=emo.get)

                    ## this block shows a separate window with live frames and edits
                    ## Use it for testing!
                    cv2.putText(frame, str(highestEmotion), (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)
                    cv2.imshow('Test', frame)
                    # cv2.waitKey(2)

                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break


                except KeyboardInterrupt:
                    cap.release()
                    cv2.destroyAllWindows()

                turnsLeft = turns
        else:
            break

    ## and when finished
    cap.release()
    cv2.destroyAllWindows()

    for key in TotalEmotionAverage:
        TotalEmotionAverage[key] = np.mean(TotalEmotionAverage[key])

    highestAvgEmotion =  max(TotalEmotionAverage, key=TotalEmotionAverage.get)
    print('The overall emotion of people in this video is: ' + highestAvgEmotion)
    return [highestAvgEmotion, TotalEmotionAverage]

def forLab(vid):
        """ Videos can only be read if they are present in the project folder """
        cap = cv2.VideoCapture(vid)
        emo = {}
        while(cap.isOpened()):
            ret, frame = cap.read()
            cv2.imwrite("current.png", frame)

            result = CF.face.detect("current.png", attributes='emotion')

            try:
                if result == []:
                    continue

                elif len(result) > 1:
                    emoList = []

                    for face in result:
                        emotes = face['faceAttributes']['emotion']
                        print(emotes)
                        emoList.append(emotes)

                        # TODO: if there is more than one face, average out emotion
                        # for now we'll take the first one

                    emo = emoList[0]
                elif len(result) == 1:
                    emo = result[0]['faceAttributes']['emotion']
                    print(emo)

                ## this block shows a separate window with live frames and edits
                ## Use it for testing!
                # cv2.putText(frame, str(highestEmotion), (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 2, 255)
                # cv2.imshow('Test', frame)
                # cv2.waitKey(2)

                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
                if emo != {}:
                    print("breaking")
                    break

            except KeyboardInterrupt:
                cap.release()
                cv2.destroyAllWindows()

        ## and when finished
        cap.release()
        cv2.destroyAllWindows()

        return emo


# findEmotions('caolanTest.mp4', 60)
